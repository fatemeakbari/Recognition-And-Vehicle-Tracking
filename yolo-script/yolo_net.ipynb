{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolo_net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "odhKaJJZuzbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN27tEjriIvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download dataset\n",
        "!wget http://detrac-db.rit.albany.edu/Data/DETRAC-train-data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nE29P6Ul6qO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"DETRAC-train-data.zip\", 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKl4ZK6Z7Bfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/yolo.zip\", 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n",
        "\n",
        "ref = zipfile.ZipFile(\"/content/drive/My Drive/labels.zip\", 'r')\n",
        "ref.extractall()\n",
        "ref.close()\n",
        "!pip install terminaltables\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-34A1PTMvmvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "from yolo import *\n",
        "from yolo.models import *\n",
        "from yolo.utils.logger import *\n",
        "from yolo.utils.utils import *\n",
        "from yolo.utils.datasets import *\n",
        "from yolo.utils.parse_config import *\n",
        "from yolo.test import evaluate\n",
        "from google.colab import files\n",
        "from terminaltables import AsciiTable\n",
        " \n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    epochs = 500\n",
        "    batch_size =10\n",
        "    gradient_accumulations = 2\n",
        "    model_def=\"yolo/config/yolov3-custom.cfg\"\n",
        "    data_config = \"yolo/config/custom.data\"\n",
        "    \n",
        "    n_cpu=  2\n",
        "    img_size = 416\n",
        "    multiscale_training=  True\n",
        "    compute_map=False\n",
        "    \n",
        "    epoch_drive=164000\n",
        "    path = \"/content/drive/My Drive/checkpoints/yolov3_ckpt_%d.pth\"% epoch_drive\n",
        "    checkpoints = torch.load(path)\n",
        "    start_epoch = checkpoints[\"epoch\"]+1\n",
        " \n",
        "    print(\"start epoch...\",start_epoch)\n",
        "    \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    data_config = parse_data_config(data_config)\n",
        "    train_path = data_config[\"train\"]\n",
        "    valid_path = data_config[\"valid\"]\n",
        "    class_names = load_classes(data_config[\"names\"])\n",
        "\n",
        "    # Initiate model\n",
        "\n",
        "  \n",
        "    model = Darknet(model_def).to(device)\n",
        "    model.apply(weights_init_normal)\n",
        "\n",
        "    # If specified we start from checkpoint\n",
        "    #[-----------------------------]\n",
        "    print(\"loading pretrained model\")\n",
        "    model.load_state_dict(checkpoints[\"model_state_dict\"])\n",
        "    print(\"finishing\")\n",
        "        # Get dataloader\n",
        "    dataset = ListDataset(train_path, augment=False, multiscale=multiscale_training)\n",
        "    print(\"dataset len: \",len(dataset))\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=n_cpu,\n",
        "        pin_memory=True,\n",
        "        collate_fn=dataset.collate_fn,\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    optimizer.load_state_dict(checkpoints['optimizer_state_dict'])\n",
        "    \n",
        "    metrics = [\n",
        "        \n",
        "        \"loss\",\n",
        "        \"x\",\n",
        "        \"y\",\n",
        "        \"w\",\n",
        "        \"h\",\n",
        "        \"conf\",\n",
        "        \"cls\"\n",
        "      \n",
        "    ]\n",
        "\n",
        "    epochs = 200000\n",
        "    path = \"/content/drive/My Drive/yololog_%d.txt\"% (start_epoch+5)\n",
        "\n",
        "    dataloader_iter = iter(dataloader)\n",
        "    message_s = \"\"\n",
        "    print(\"start...\")\n",
        "\n",
        "    total_loss_print = 0\n",
        "    total_loss_print_num = 0\n",
        "    with open(path, \"w\") as log:\n",
        "\n",
        "      for epoch in range(start_epoch,epochs):\n",
        "\n",
        "          model.train()\n",
        "          start_time = time.time()\n",
        "\n",
        "          try:\n",
        "              _, imgs, targets = next(dataloader_iter)\n",
        "          except StopIteration:\n",
        "              dataloader_iter = iter(dataloader)\n",
        "              _, imgs, targets = next(dataloader_iter)\n",
        "\n",
        "          imgs = Variable(imgs.to(device))\n",
        "          targets = Variable(targets.to(device), requires_grad=False)\n",
        "\n",
        "          loss, outputs = model(imgs, targets)\n",
        "          loss.backward()\n",
        "\n",
        "      \n",
        "          optimizer.step()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "\n",
        "          log_str = \"\\n---- [Epoch %d] ----\\n\" % (epoch)\n",
        "\n",
        "          metric_table = [[\"Metrics\", *[f\"YOLO Layer {i}\" for i in range(len(model.yolo_layers))]]]\n",
        "\n",
        "          # Log metrics at each YOLO layer\n",
        "          message=\"\"\n",
        "          message = str(epoch)+\" \"\n",
        "          for i, metric in enumerate(metrics):\n",
        "              formats = {m: \"%.6f\" for m in metrics}\n",
        "              formats[\"grid_size\"] = \"%2d\"\n",
        "              formats[\"cls_acc\"] = \"%.2f%%\"\n",
        "              row_metrics = [formats[metric] % yolo.metrics.get(metric, 0) for yolo in model.yolo_layers]\n",
        "              #print(\"r_m\",row_metrics)\n",
        "              #print(\"m: \",metric,\" r_m:\", *row_metrics)\n",
        "              message += str(metric)+\" \"+str(float(row_metrics[0])+float(row_metrics[1])+float(row_metrics[2]))+\" \"\n",
        "              metric_table += [[metric, *row_metrics]]\n",
        "\n",
        "              # Tensorboard logging\n",
        "              tensorboard_log = []\n",
        "              for j, yolo in enumerate(model.yolo_layers):\n",
        "                  for name, metric in yolo.metrics.items():\n",
        "                      if name != \"grid_size\":\n",
        "                          tensorboard_log += [(f\"{name}_{j+1}\", metric)]\n",
        "              tensorboard_log += [(\"loss\", loss.item())]\n",
        "              #logger.list_of_scalars_summary(tensorboard_log, batches_done)\n",
        "          total_loss_print += loss.item();\n",
        "          total_loss_print_num += 1\n",
        "          message +=\"\\n\"\n",
        "          message_s += message\n",
        "          log_str += AsciiTable(metric_table).table\n",
        "          log_str += f\"\\nTotal loss {loss.item()}\"\n",
        "\n",
        "          log.write(message)\n",
        "          log.flush()\n",
        "          \n",
        "          model.seen += imgs.size(0)\n",
        "          if(epoch % 2000 == 0):\n",
        "            print(message)\n",
        "            print(\"tota;\" ,total_loss_print/total_loss_print_num)\n",
        "            total_loss_print_num = 0\n",
        "            total_loss_print = 0\n",
        "            \n",
        "          if epoch % 4000 == 0:\n",
        "             \n",
        "              print(\"saving...\")\n",
        "              \n",
        "              print(message)\n",
        "              \n",
        "              saving_file = {\n",
        "              'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              \n",
        "              }\n",
        "              \n",
        "              torch.save(saving_file, f\"/content/drive/My Drive/checkpoints/yolov3_ckpt_%d.pth\" % epoch)\n",
        "              th_file = open(\"/content/drive/My Drive/yololog_message_%d.txt\" % epoch, \"w\")\n",
        "              th_file.write(message_s)\n",
        "              th_file.close()\n",
        "              message_s = \"\"\n",
        "              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvzmWWXKyoVU",
        "colab_type": "code",
        "outputId": "fbf0eb4e-48f1-4eee-e237-4ee7331f53f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "##--------------------EVAL-------------------------------\n",
        "from __future__ import division\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "from yolo import *\n",
        "from yolo.models import *\n",
        "from yolo.utils.logger import *\n",
        "from yolo.utils.utils import *\n",
        "from yolo.utils.datasets import *\n",
        "from yolo.utils.parse_config import *\n",
        "from yolo.test import evaluate\n",
        "from google.colab import files\n",
        "from terminaltables import AsciiTable\n",
        " \n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "def evaluate(model, path, iou_thres, conf_thres, nms_thres, img_size, batch_size):\n",
        "    model.eval()\n",
        "\n",
        "    # Get dataloader\n",
        "    dataset = ListDataset(path, img_size=img_size, augment=False, multiscale=False)\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=False, num_workers=1, collate_fn=dataset.collate_fn\n",
        "    )\n",
        "\n",
        "    Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "\n",
        "    labels = []\n",
        "    sample_metrics = []  # List of tuples (TP, confs, pred)\n",
        "    for batch_i, (_, imgs, targets) in enumerate(tqdm.tqdm(dataloader, desc=\"Detecting objects\")):\n",
        "\n",
        "        # Extract labels\n",
        "        labels += targets[:, 1].tolist()\n",
        "        # Rescale target\n",
        "        targets[:, 2:] = xywh2xyxy(targets[:, 2:])\n",
        "        targets[:, 2:] *= img_size\n",
        "\n",
        "        imgs = Variable(imgs.type(Tensor), requires_grad=False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(imgs)\n",
        "            outputs = non_max_suppression(outputs, conf_thres=conf_thres, nms_thres=nms_thres)\n",
        "\n",
        "        sample_metrics += get_batch_statistics(outputs, targets, iou_threshold=iou_thres)\n",
        "\n",
        "    # Concatenate sample statistics\n",
        "    true_positives, pred_scores, pred_labels = [np.concatenate(x, 0) for x in list(zip(*sample_metrics))]\n",
        "    precision, recall, AP, f1, ap_class = ap_per_class(true_positives, pred_scores, pred_labels, labels)\n",
        "    print(precision, recall, AP, f1, ap_class)\n",
        "    return precision, recall, AP, f1, ap_class\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_def=\"yolo/config/yolov3-custom.cfg\"\n",
        "data_config = \"yolo/config/custom.data\"\n",
        "\n",
        "multiscale_training=  True\n",
        "compute_map=False\n",
        "\n",
        "epoch_drive=168000\n",
        "path = \"/content/drive/My Drive/checkpoints/yolov3_ckpt_%d.pth\"% epoch_drive\n",
        "checkpoints = torch.load(path)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Get data configuration\n",
        "data_config = parse_data_config(data_config)\n",
        "train_path = data_config[\"train\"]\n",
        "valid_path = data_config[\"valid\"]\n",
        "class_names = load_classes(data_config[\"names\"])\n",
        "\n",
        "# Initiate model\n",
        "\n",
        "\n",
        "model = Darknet(model_def).to(device)\n",
        "model.apply(weights_init_normal)\n",
        "\n",
        "model.load_state_dict(checkpoints[\"model_state_dict\"])\n",
        "print(\"finish load\")\n",
        "\n",
        "\n",
        "precision, recall, AP, f1, ap_class = evaluate(\n",
        "                model,\n",
        "                path=valid_path,\n",
        "                iou_thres=0.5,\n",
        "                conf_thres=0.5,\n",
        "                nms_thres=0.5,\n",
        "                img_size=416,\n",
        "                batch_size=8,\n",
        "            )\n",
        "evaluation_metrics = [\n",
        "    (\"val_precision\", precision.mean()),\n",
        "    (\"val_recall\", recall.mean()),\n",
        "    (\"val_mAP\", AP.mean()),\n",
        "    (\"val_f1\", f1.mean()),\n",
        "]\n",
        "\n",
        "print(evaluation_metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rDetecting objects:   0%|          | 0/539 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finish load\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Detecting objects: 100%|██████████| 539/539 [02:17<00:00,  3.91it/s]\n",
            "Computing AP: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.83225172] [0.90669523] [0.81970218] [0.86788003] [0]\n",
            "[('val_precision', 0.8322517207472959), ('val_recall', 0.9066952329941081), ('val_mAP', 0.8197021765661301), ('val_f1', 0.8678800307613432)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-wxmAuQ64kd",
        "colab_type": "code",
        "outputId": "077b697c-f31f-4b33-a656-9cbfca19354f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#detect image test\n",
        "\n",
        "from __future__ import division\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "from yolo import *\n",
        "from yolo.models import *\n",
        "from yolo.utils.utils import *\n",
        "from yolo.utils.datasets import *\n",
        "from yolo.utils.parse_config import *\n",
        "from yolo.test import evaluate\n",
        "from terminaltables import AsciiTable\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.ticker import NullLocator\n",
        "import cv2\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "path =  \"/content/drive/My Drive/checkpoints/yolov3_ckpt_%d.pth\"% 168000\n",
        "checkpoints = torch.load(path)\n",
        "\n",
        "\n",
        "data_config = \"yolo/config/custom.data\"\n",
        "data_config = parse_data_config(data_config)\n",
        "model_def = \"yolo/config/yolov3-custom.cfg\"\n",
        "conf_thres = 0.6\n",
        "nms_thres = 0.4\n",
        "batch_size = 1\n",
        "img_size=416\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "class_names = load_classes(data_config[\"names\"])\n",
        "print(1)\n",
        "\n",
        "# Initiate model\n",
        "model = Darknet(model_def).to(device)\n",
        "model.apply(weights_init_normal)\n",
        "\n",
        "model.load_state_dict(checkpoints[\"model_state_dict\"])\n",
        "model.eval()\n",
        "\n",
        "\n",
        "im = cv2.imread('./Insight-MVT_Annotation_Train/MVI_20061/img00300.jpg')\n",
        "im = cv2.resize(im,(416,416))\n",
        "img = transforms.ToTensor()(im)\n",
        "img = img.unsqueeze(0)\n",
        "s_time = time.time()\n",
        "detections = model(Variable(img.cuda()))\n",
        "e_time=  time.time()\n",
        "\n",
        "print(\"dff: \",e_time - s_time)\n",
        "detections = non_max_suppression(detections, 0.5, 0.5)\n",
        "\n",
        "for d in detections[0].cpu().detach().numpy():\n",
        "  x1 = d[0]\n",
        "  y1 = d[1]\n",
        "  x2 = d[2]\n",
        "  y2 = d[3]\n",
        "  cv2.rectangle(im,(x1,y1),(x2,y2),(255,0,0),2)\n",
        "\n",
        "cv2.imwrite(\"output/\"+'out.jpg',im)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "dff:  0.03576350212097168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiFtCDrgMM_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install filterpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA-RrSN8HCPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#track video for calculate accuracy\n",
        "\n",
        "from sort import *\n",
        "\n",
        "%matplotlib inline\n",
        "from __future__ import division\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "from yolo import *\n",
        "from yolo.models import *\n",
        "from yolo.utils.utils import *\n",
        "from yolo.utils.datasets import *\n",
        "from yolo.utils.parse_config import *\n",
        "from yolo.test import evaluate\n",
        "from terminaltables import AsciiTable\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "VIDEO_SAVE_DIR=\"traffic_result\"\n",
        "if(os.path.exists(VIDEO_SAVE_DIR)):\n",
        "  !rm -r traffic_result\n",
        "  os.mkdir(VIDEO_SAVE_DIR)\n",
        "else:\n",
        "  os.mkdir(VIDEO_SAVE_DIR)\n",
        "\n",
        "COLORS = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
        "start_epoch=50000\n",
        "path =  \"/content/drive/My Drive/checkpoints/yolov3_ckpt_%d.pth\"% 168000\n",
        "checkpoints = torch.load(path)\n",
        "\n",
        "data_config = \"yolo/config/custom.data\"\n",
        "data_config = parse_data_config(data_config)\n",
        "model_def = \"yolo/config/yolov3-custom.cfg\"\n",
        "conf_thres = 0.6\n",
        "nms_thres = 0.4\n",
        "batch_size = 1\n",
        "img_size=416\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "class_names = load_classes(data_config[\"names\"])\n",
        "\n",
        "# Initiate model\n",
        "model = Darknet(model_def).to(device)\n",
        "model.apply(weights_init_normal)\n",
        "\n",
        "model.load_state_dict(checkpoints[\"model_state_dict\"])\n",
        "model.eval()\n",
        "\n",
        "\n",
        "\n",
        "frames = []\n",
        "frame_count=0\n",
        "mot_tracker = Sort()\n",
        "\n",
        "the_file = open('test_tracking.txt')\n",
        "list_of_test_img = []\n",
        "\n",
        "for line in the_file:\n",
        "  list_of_test_img.append(line.strip())\n",
        "\n",
        "\n",
        "list_of_test_img = sorted(list_of_test_img)\n",
        "\n",
        "all_ = []\n",
        "path = \"/content/Insight-MVT_Annotation_Train/\"\n",
        "\n",
        "\n",
        "for filename in list_of_test_img:\n",
        "    frame = cv2.imread(path+str(filename),1)\n",
        "    frame_count += 1\n",
        "  \n",
        "    im = cv2.resize(frame,(416,416))\n",
        "    img = transforms.ToTensor()(im)\n",
        "    img = img.unsqueeze(0)\n",
        "    detections = model(Variable(img.cuda()))\n",
        "    \n",
        "    detections = non_max_suppression(detections, 0.5, 0.5)\n",
        "    if(detections[0] != None):\n",
        "\n",
        "      detections = detections[0].cpu().detach().numpy()\n",
        "      if detections.size != 0:\n",
        "      \n",
        "        trackers = mot_tracker.update(detections)\n",
        "      \n",
        "        for d in trackers:\n",
        "          try:\n",
        "              xmin=int((d[0]/float(416)) * 960)\n",
        "              ymin=int((d[1]/float(416))*540)\n",
        "              xmax=int((d[2]/float(416))*960)\n",
        "              ymax=int((d[3]/float(416))*540)\n",
        "              label=int(d[4])\n",
        "              cv2.rectangle(im,(xmin,ymin),(xmax,ymax),(255,0,0),2)\n",
        "              cv2.putText(im, str(label), (int(xmin), int(ymin)),\n",
        "                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "              #cv2_imshow(frame)\n",
        "              #cv2.waitKey(1)\n",
        "              all_.append([filename,label,xmin,ymin,xmax,ymax])\n",
        "          except:\n",
        "            print(\"error\")            \n",
        "    \n",
        "    \n",
        "    if(frame_count % 100==0):\n",
        "      print(frame_count)\n",
        "   \n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(all_, columns=[\"name\",\"label\",\"x1\",\"y1\",'x2','y2'])\n",
        "df.to_csv('yolo_track_out.csv', index=False) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6LveCUnMGoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install filterpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfx7jy63OArp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#track video\n",
        "\n",
        "from sort import *\n",
        "\n",
        "%matplotlib inline\n",
        "from __future__ import division\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "from yolo import *\n",
        "from yolo.models import *\n",
        "from yolo.utils.utils import *\n",
        "from yolo.utils.datasets import *\n",
        "from yolo.utils.parse_config import *\n",
        "from yolo.test import evaluate\n",
        "from terminaltables import AsciiTable\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "VIDEO_SAVE_DIR=\"traffic_result\"\n",
        "if(os.path.exists(VIDEO_SAVE_DIR)):\n",
        "  !rm -r traffic_result\n",
        "  os.mkdir(VIDEO_SAVE_DIR)\n",
        "else:\n",
        "  os.mkdir(VIDEO_SAVE_DIR)\n",
        "\n",
        "COLORS = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
        "start_epoch=50000\n",
        "path =  \"/content/drive/My Drive/checkpoints/yolov3_ckpt_%d.pth\"% 168000\n",
        "checkpoints = torch.load(path)\n",
        "\n",
        "data_config = \"yolo/config/custom.data\"\n",
        "data_config = parse_data_config(data_config)\n",
        "model_def = \"yolo/config/yolov3-custom.cfg\"\n",
        "conf_thres = 0.6\n",
        "nms_thres = 0.4\n",
        "batch_size = 1\n",
        "img_size=416\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "class_names = load_classes(data_config[\"names\"])\n",
        "\n",
        "# Initiate model\n",
        "model = Darknet(model_def).to(device)\n",
        "model.apply(weights_init_normal)\n",
        "\n",
        "model.load_state_dict(checkpoints[\"model_state_dict\"])\n",
        "model.eval()\n",
        "\n",
        "\n",
        "$capture = cv2.VideoCapture(\"/content/drive/My Drive/checkpoints/b_traffic.mp4\")\n",
        "\n",
        "frames = []\n",
        "frame_count=0\n",
        "mot_tracker = Sort()\n",
        "\n",
        "frame_path = []\n",
        "for name in os.listdir(\"/content/Insight-MVT_Annotation_Train/MVI_40131\"):\n",
        "  frame_path.append(\"/content/Insight-MVT_Annotation_Train/MVI_40131/\"+name)\n",
        "\n",
        "frame_path = sorted(frame_path)\n",
        "for path in frame_path:\n",
        "\n",
        "\n",
        "# while True:\n",
        "#     ret, frame = capture.read()\n",
        "  \n",
        "    # Bail out when the video file ends\n",
        "    frame = cv2.imread(path)\n",
        "    # if not ret:\n",
        "    #     break        \n",
        "    # Save each frame of the video to a list\n",
        "    frame_count += 1\n",
        "\n",
        "    im = cv2.resize(frame,(416,416))\n",
        "    img = transforms.ToTensor()(im)\n",
        "    img = img.unsqueeze(0)\n",
        "    detections = model(Variable(img.cuda()))\n",
        "    detections = non_max_suppression(detections, 0.5, 0.5)\n",
        "    detections = detections[0].cpu().detach().numpy()\n",
        "    if detections.size != 0:\n",
        "     \n",
        "      trackers = mot_tracker.update(detections)\n",
        "    \n",
        "      for d in trackers:\n",
        "        try:\n",
        "            xmin=int((d[0]/416) * 916)\n",
        "            ymin=int((d[1]/416) * 540)\n",
        "            xmax=int((d[2]/416) * 916)\n",
        "            ymax=int((d[3]/416) * 540)\n",
        "            label=int(d[4])\n",
        "            cv2.rectangle(frame,(xmin,ymin),(xmax,ymax),(255,0,0),2)\n",
        "            cv2.putText(frame, str(label), (int(xmin), int(ymin)),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "            #cv2_imshow(frame)\n",
        "            #cv2.waitKey(1)\n",
        "        except:\n",
        "          print(\"error\")            \n",
        "      \n",
        "    if(frame_count % 100==0):\n",
        "      print(frame_count)\n",
        "   \n",
        "\n",
        "    name = '{}.jpg'.format(frame_count)\n",
        "    name = os.path.join(VIDEO_SAVE_DIR, name)\n",
        "    cv2.imwrite(name, frame)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "##############CONVERT TRACKED IMAGE TO VIDEO###################\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "# video = cv2.VideoCapture(\"/content/drive/My Drive/checkpoints/b_traffic.mp4\");\n",
        "\n",
        "\n",
        "# # Find OpenCV version\n",
        "# (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
        "\n",
        "# if int(major_ver)  < 3 :\n",
        "#     fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
        "#     print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
        "# else :\n",
        "#     fps = video.get(cv2.CAP_PROP_FPS)\n",
        "#     print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
        "fps= 25\n",
        "video.release();\n",
        "\n",
        "def make_video(outvid, images=None, fps=30, size=None,\n",
        "               is_color=True, format=\"FMP4\"):\n",
        "  \n",
        "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
        "    fourcc = VideoWriter_fourcc(*format)\n",
        "    vid = None\n",
        "    for image in images:\n",
        "        #print(image)\n",
        "        if not os.path.exists(image):\n",
        "            raise FileNotFoundError(image)\n",
        "        img = imread(image)\n",
        "        if vid is None:\n",
        "            if size is None:\n",
        "                size = img.shape[1], img.shape[0]\n",
        "            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n",
        "        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
        "            img = resize(img, size)\n",
        "        vid.write(img)\n",
        "    vid.release()\n",
        "    return vid\n",
        "\n",
        "\n",
        "\n",
        "images = list(glob.iglob(os.path.join(\"traffic_result\", '*.*')))\n",
        "# Sort the images by name index.\n",
        "images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))  \n",
        "\n",
        "outvid =  \"/content/drive/My Drive/yolo_out.mp4\"\n",
        "make_video(outvid, images, fps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56VKpZEc-3gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}