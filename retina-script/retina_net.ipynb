{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "retina_net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHKnJGZB_saL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG8cfFOlU8tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/retinanet.zip\", 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n",
        "#path of train and val annotation\n",
        "ref = zipfile.ZipFile(\"/content/drive/My Drive/data.zip\", 'r')\n",
        "ref.extractall()\n",
        "ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kFy56RaJmCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download dataset\n",
        "!wget http://detrac-db.rit.albany.edu/Data/DETRAC-train-data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoO7z_d5q1ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_ref = zipfile.ZipFile(\"DETRAC-train-data.zip\", 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXuP9dWKUheN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2p64iFzCW2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "\n",
        "from retinanet import model\n",
        "from retinanet.dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, \\\n",
        "    Normalizer\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from retinanet import coco_eval\n",
        "from retinanet import csv_eval\n",
        "\n",
        "assert torch.__version__.split('.')[0] == '1'\n",
        "\n",
        "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
        "\n",
        "\n",
        "csv_train = \"./data/retina_train.csv\"\n",
        "csv_classes = \"./data/class.csv\"\n",
        "csv_val = \"./data/retina_test.csv\"\n",
        "depth = 50\n",
        "batch_size = 4\n",
        "def main(args=None):\n",
        "  \n",
        "    if csv_train is None:\n",
        "        raise ValueError('Must provide --csv_train when training on COCO,')\n",
        "\n",
        "    if csv_classes is None:\n",
        "        raise ValueError('Must provide --csv_classes when training on COCO,')\n",
        "\n",
        "    dataset_train = CSVDataset(train_file=csv_train, class_list=csv_classes,\n",
        "                                transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n",
        "\n",
        "    if csv_val is None:\n",
        "        dataset_val = None\n",
        "        print('No validation annotations provided.')\n",
        "    else:\n",
        "        dataset_val = CSVDataset(train_file=csv_val, class_list=csv_classes,\n",
        "                                  transform=transforms.Compose([Normalizer(), Resizer()]))\n",
        "\n",
        "  \n",
        "    \n",
        "    sampler = AspectRatioBasedSampler(dataset_train, batch_size=batch_size, drop_last=False)\n",
        "    dataloader_train = DataLoader(dataset_train, num_workers=4, collate_fn=collater, batch_sampler=sampler)\n",
        "\n",
        "    if dataset_val is not None:\n",
        "        sampler_val = AspectRatioBasedSampler(dataset_val, batch_size=batch_size, drop_last=False)\n",
        "        dataloader_val = DataLoader(dataset_val, num_workers=4, collate_fn=collater, batch_sampler=sampler_val)\n",
        "\n",
        "    # Create the model\n",
        "    if depth == 18:\n",
        "        retinanet = model.resnet18(num_classes=dataset_train.num_classes(), pretrained=True)\n",
        "    elif depth == 34:\n",
        "        retinanet = model.resnet34(num_classes=dataset_train.num_classes(), pretrained=True)\n",
        "    elif depth == 50:\n",
        "        retinanet = model.resnet50(num_classes=dataset_train.num_classes(), pretrained=True)\n",
        "    elif depth == 101:\n",
        "        retinanet = model.resnet101(num_classes=dataset_train.num_classes(), pretrained=True)\n",
        "    elif depth == 152:\n",
        "        retinanet = model.resnet152(num_classes=dataset_train.num_classes(), pretrained=True)\n",
        "    else:\n",
        "        raise ValueError('Unsupported model depth, must be one of 18, 34, 50, 101, 152')\n",
        "\n",
        "    use_gpu = True\n",
        "\n",
        "    if use_gpu:\n",
        "        retinanet = retinanet.cuda()\n",
        "\n",
        "    #---\n",
        "    start_iter = 99000\n",
        "    path = \"/content/drive/My Drive/retina_checkpoints/retina_ckpt_%d.pt\" % start_iter\n",
        "    load_checkpoints = torch.load(path)\n",
        "    \n",
        "\n",
        "    retinanet = torch.nn.DataParallel(retinanet).cuda()\n",
        "    retinanet.load_state_dict( load_checkpoints['model'])\n",
        "\n",
        "    retinanet.training = True\n",
        "\n",
        "    optimizer = optim.Adam(retinanet.parameters(), lr=1e-5)\n",
        "    #--\n",
        "    optimizer.load_state_dict(load_checkpoints['optimizer_state_dict'])\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
        "\n",
        "    loss_hist = collections.deque(maxlen=500)\n",
        "\n",
        "    retinanet.train()\n",
        "    retinanet.module.freeze_bn()\n",
        "    total_iter = 100000\n",
        "\n",
        "    print('Num training images: {}'.format(len(dataset_train)))\n",
        "    log_path = \"/content/drive/My Drive/retina_log_%d.txt\"% (start_iter+1000)\n",
        "  \n",
        "    train_iterator = iter(dataloader_train)\n",
        "    \n",
        "    epoch_loss = []\n",
        "    num_loss = 0\n",
        "    all_loss = 0\n",
        "    message_s= \"\"\n",
        "    total_loss_print = 0\n",
        "    total_loss_print_num=0\n",
        "    \n",
        "    for iter_num in range(start_iter+1, total_iter):\n",
        "\n",
        "        retinanet.train()\n",
        "        retinanet.module.freeze_bn()\n",
        "        try:\n",
        "            data = next(train_iterator)\n",
        "        except StopIteration:\n",
        "            train_iterator = iter(dataloader_train)\n",
        "            data = next(train_iterator)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        classification_loss, regression_loss = retinanet([data['img'].cuda().float(), data['annot']])\n",
        "\n",
        "        classification_loss = classification_loss.mean()\n",
        "        regression_loss = regression_loss.mean()\n",
        "\n",
        "        loss = classification_loss + regression_loss\n",
        "\n",
        "        if bool(loss == 0):\n",
        "            continue\n",
        "        all_loss += loss\n",
        "        num_loss+=1\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        loss_hist.append(float(loss))\n",
        "        epoch_loss.append(float(loss))\n",
        "        log = 'Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n",
        "                  iter_num, float(classification_loss), float(regression_loss), float(loss))\n",
        "        \n",
        "        message_s += log+\"\\n\"\n",
        "      \n",
        "        del classification_loss\n",
        "        del regression_loss\n",
        "    \n",
        "        if iter_num % 1000 == 0:\n",
        "\n",
        "          print(\"iter_num: \",iter_num, \" \",all_loss/num_loss)\n",
        "          all_loss = 0\n",
        "          num_loss = 0\n",
        "\n",
        "        if iter_num % 4000== 0:\n",
        "          print(\"saving...\")\n",
        "          saving_file = {\n",
        "            'model': retinanet.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()\n",
        "            \n",
        "            }\n",
        "          torch.save(saving_file, f\"/content/drive/My Drive/retina_checkpoints/retina_ckpt_%d.pt\" % iter_num) \n",
        "          \n",
        "          torch.save(retinanet.module, f\"/content/drive/My Drive/retina_checkpoints/retina_%d.pt\" % iter_num)\n",
        "          th_file = open(\"/content/drive/My Drive/retina_message%d.txt\" % iter_num,\"w\")\n",
        "          th_file.write(message_s)\n",
        "          th_file.close()\n",
        "          message_s = \"\"\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHWADrTT49l9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#eval script\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "import argparse\n",
        "import collections\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "\n",
        "from retinanet import model\n",
        "from retinanet.dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, \\\n",
        "    Normalizer\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from retinanet import coco_eval\n",
        "from retinanet import csv_eval\n",
        "\n",
        "assert torch.__version__.split('.')[0] == '1'\n",
        "\n",
        "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
        "\n",
        "dataset = \"csv\"\n",
        "csv_train = \"./data/retina_train.csv\"\n",
        "csv_classes = \"./data/class.csv\"\n",
        "csv_val = \"./data/retina_test.csv\"\n",
        "depth = 50\n",
        "\n",
        "def main(args=None):\n",
        "\n",
        "    dataset_val = CSVDataset(train_file=csv_val, class_list=csv_classes,\n",
        "                                     transform=transforms.Compose([Normalizer(), Resizer()]))\n",
        "\n",
        "    if depth == 50:\n",
        "        retinanet = model.resnet50(num_classes=dataset_val.num_classes(), pretrained=True)\n",
        "    use_gpu = True\n",
        "\n",
        "    if use_gpu:\n",
        "        retinanet = retinanet.cuda()\n",
        "    path = \"/content/drive/My Drive/retina_checkpoints/retina_ckpt_%d.pt\" % 99000\n",
        "    load_checkpoints = torch.load(path)\n",
        "\n",
        "    retinanet = torch.nn.DataParallel(retinanet).cuda()\n",
        "    retinanet.load_state_dict(load_checkpoints['model'])\n",
        "    retinanet.eval()\n",
        "\n",
        "    mAP,r,p,f1 = csv_eval.evaluate(dataset_val, retinanet)\n",
        "\n",
        "    print(\"val\")\n",
        "    print(\"map: \", mAP)\n",
        "    print(\"recall: \",r)\n",
        "    print(\"precision: \",p)\n",
        "    print(\"f1_score: \",f1)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeZtHjp36pXr",
        "colab_type": "code",
        "outputId": "99020866-1d4b-41ba-9b31-53b026cb4f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#detect test image\n",
        "\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import pdb\n",
        "import time\n",
        "import argparse\n",
        "import skimage.io\n",
        "import skimage.transform\n",
        "import skimage.color\n",
        "import skimage\n",
        "\n",
        "from PIL import Image\n",
        "import sys\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from retinanet.dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, \\\n",
        "\tUnNormalizer, Normalizer\n",
        "\n",
        "import zipfile\n",
        "\n",
        "\n",
        "from torch.autograd import Variable\n",
        "assert torch.__version__.split('.')[0] == '1'\n",
        "from google.colab.patches import cv2_imshow\n",
        "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
        "import time\n",
        "\n",
        "def main(args=None):\n",
        "\tparser = argparse.ArgumentParser(description='Simple training script for training a RetinaNet network.')\n",
        "\n",
        "\n",
        "\tpath = \"/content/drive/My Drive/retina_checkpoints/retina_%d.pt\" % 99000\n",
        "\tretinanet = torch.load(path)\n",
        "\n",
        "\tuse_gpu = True\n",
        "\n",
        "\tif use_gpu:\n",
        "\t\tretinanet = retinanet.cuda()\n",
        "\n",
        "\tretinanet.eval()\n",
        "\n",
        "\tunnormalize = UnNormalizer()\n",
        "\n",
        "\tdef draw_caption(image, box, caption):\n",
        "\n",
        "\t\tb = np.array(box).astype(int)\n",
        "\t\tcv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
        "\t\tcv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1)\n",
        "\n",
        "\n",
        "\tim = skimage.io.imread(\"./Insight-MVT_Annotation_Train/MVI_20061/img00300.jpg\")\n",
        " \n",
        "\tmain_im=  cv2.imread(\"./Insight-MVT_Annotation_Train/MVI_20061/img00300.jpg\",1)\n",
        " \n",
        "\tif len(im.shape) == 2:\n",
        "\t\tim = skimage.color.gray2rgb(im)\n",
        "\tim = im.astype(np.float32)/255.0\n",
        "\tim = torch.from_numpy(im)\n",
        "\tim = im.permute(2, 0, 1)\n",
        "\tim = Variable(im.unsqueeze(0))\n",
        "\tprint(im.shape)\n",
        "\n",
        "\twith torch.no_grad():\n",
        "\t\tst = time.time()\n",
        "\t\n",
        "\t\tscores, classification, transformed_anchors = retinanet(im.cuda().float())\t\n",
        "\t\tprint(\"diff time \",time.time() - st)\n",
        "\t\tidxs = np.where(scores.cpu()>0.5)\n",
        "\t\timg = np.array(255 * unnormalize(im[0, :, :, :])).copy()\n",
        "\n",
        "\t\timg[img<0] = 0\n",
        "\t\timg[img>255] = 255\n",
        "\n",
        "\t\timg = np.transpose(img, (1, 2, 0))\n",
        "\n",
        "\t\timg = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\t\tfor j in range(idxs[0].shape[0]):\n",
        "\t\t\tbbox = transformed_anchors[idxs[0][j], :]\n",
        "\t\t\tx1 = int(bbox[0])\n",
        "\t\t\ty1 = int(bbox[1])\n",
        "\t\t\tx2 = int(bbox[2])\n",
        "\t\t\ty2 = int(bbox[3])\n",
        "\t\t\n",
        "\n",
        "\t\t\tcv2.rectangle(main_im, (x1, y1), (x2, y2), color=(0, 0, 255), thickness=2)\n",
        "\t\t\t\n",
        "\n",
        "\t\tcv2.imwrite(str(1)+\".jpg\",main_im)\n",
        "\t\t\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        " main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "torch.Size([1, 3, 540, 960])\n",
            "diff time  0.10545849800109863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y9iRxGMXB1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install filterpy\n",
        "from sort import *\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9KtHsBuJGPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tracking script\n",
        "\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import pdb\n",
        "import time\n",
        "import argparse\n",
        "from sort import *\n",
        "import sys\n",
        "import cv2\n",
        "from skimage import io\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from retinanet.dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, \\\n",
        "\tUnNormalizer, Normalizer\n",
        "\n",
        "import zipfile\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
        "\n",
        "\n",
        "VIDEO_SAVE_DIR=\"traffic_result\"\n",
        "if(os.path.exists(VIDEO_SAVE_DIR)):\n",
        "  !rm -r traffic_result\n",
        "  os.mkdir(VIDEO_SAVE_DIR)\n",
        "else:\n",
        "  os.mkdir(VIDEO_SAVE_DIR)\n",
        "\n",
        "path = \"/content/drive/My Drive/retina_checkpoints/retina_%d.pt\" % 99000\n",
        "\n",
        "retinanet = torch.load(path)\n",
        "\n",
        "retinanet = retinanet.cuda()\n",
        "retinanet.eval()\n",
        "\n",
        "unnormalize = UnNormalizer()\n",
        "\n",
        "mot_tracker= Sort()\n",
        "\n",
        "from skimage import io\n",
        "\n",
        "import skimage\n",
        "frames = []\n",
        "frame_count=0\n",
        "mot_tracker = Sort()\n",
        "capture = cv2.VideoCapture(\"/content/drive/My Drive/b_traffic.mp4\")\n",
        "\n",
        "frame_path = []\n",
        "for name in os.listdir(\"/content/Insight-MVT_Annotation_Train/MVI_40131\"):\n",
        "  frame_path.append(\"/content/Insight-MVT_Annotation_Train/MVI_40131/\"+name)\n",
        "\n",
        "frame_path = sorted(frame_path)\n",
        "for path in frame_path:\n",
        "    frame = cv2.imread(path)\n",
        "    # ret, frame = capture.read()\n",
        "    # if not ret:\n",
        "    #     break \n",
        "    #frame = frame.astype(np.float32)  \n",
        "    #frame = cv2.imread(\"11.jpg\")\n",
        "    frame = cv2.resize(frame,(1056, 608))  \n",
        "    frame2 = frame.copy()\n",
        "    img = frame.copy()\n",
        "    img = cv2.resize(img,(1056, 608))  \n",
        "    \n",
        "    img = img.astype(np.float32)/255.0\n",
        "    img = torch.from_numpy(img.copy()).float()\n",
        "    img = img.permute(2, 0, 1)\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "    height, width = frame.shape[:2]\n",
        "    \n",
        "    \n",
        "    # Bail out when the video file ends\n",
        "           \n",
        "    # Save each frame of the video to a list\n",
        "    scores, classification, transformed_anchors = retinanet(img.cuda().float())\t\n",
        "    boxes = transformed_anchors.cpu().detach().numpy()\n",
        "    scores_ = scores.cpu().detach().numpy()\n",
        "    s = scores_.reshape(scores_.shape[0],1)\n",
        "    result = np.concatenate((boxes,s), axis=1)\n",
        "    \n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    if result.size != 0:\n",
        "      #trackers_objects  = mot_tracker.update(detections)\n",
        "      trackers = mot_tracker.update(result)\n",
        "\n",
        "      for d in trackers:\n",
        "            #print(\"d\",d)\n",
        "            xmin=int(d[0])\n",
        "            ymin=int(d[1])\n",
        "            xmax=int(d[2])\n",
        "            ymax=int(d[3])\n",
        "            label=int(d[4])\n",
        "            cv2.rectangle(frame2,(xmin,ymin),(xmax,ymax),(0,0,255),2)\n",
        "            cv2.putText(frame2, str(label), (int(xmin), int(ymin)),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "      \n",
        "\n",
        "    if(frame_count % 100==0):\n",
        "      print(frame_count)\n",
        "  \n",
        "   \n",
        "    name = '{}.jpg'.format(frame_count)\n",
        "    name = os.path.join(VIDEO_SAVE_DIR, name)\n",
        "    cv2.imwrite(name, frame2)\n",
        "  \n",
        "\n",
        "\n",
        "#convert tracked image to video\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "video = cv2.VideoCapture(\"/content/drive/My Drive/b_traffic.mp4\");\n",
        "\n",
        "# Find OpenCV version\n",
        "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
        "\n",
        "if int(major_ver)  < 3 :\n",
        "    fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
        "    print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
        "else :\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "    print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
        "fps=25\n",
        "video.release();\n",
        "\n",
        "def make_video(outvid, images=None, fps=30, size=None,\n",
        "               is_color=True, format=\"FMP4\"):\n",
        "  \n",
        "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
        "    fourcc = VideoWriter_fourcc(*format)\n",
        "    vid = None\n",
        "    for image in images:\n",
        "        #print(image)\n",
        "        if not os.path.exists(image):\n",
        "            raise FileNotFoundError(image)\n",
        "        img = imread(image)\n",
        "        if vid is None:\n",
        "            if size is None:\n",
        "                size = img.shape[1], img.shape[0]\n",
        "            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n",
        "        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
        "            img = resize(img, size)\n",
        "        vid.write(img)\n",
        "    vid.release()\n",
        "    return vid\n",
        "\n",
        "\n",
        "\n",
        "images = list(glob.iglob(os.path.join(\"traffic_result\", '*.*')))\n",
        "# Sort the images by name index.\n",
        "images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))  \n",
        "\n",
        "outvid =  \"/content/drive/My Drive/retina_out.mp4\"\n",
        "make_video(outvid, images, fps)\n",
        "\t \t\n",
        "\n",
        "\t\t\t\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVa38VFTVPGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-------------------------CALCULATE ACCURACY TRACKING-------------------------------\n",
        "\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import pdb\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "import sys\n",
        "import cv2\n",
        "from skimage import io\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from sort import *\n",
        "\n",
        "import zipfile\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
        "\n",
        "\n",
        "path = \"/content/drive/My Drive/retina_checkpoints/retina_%d.pt\" % 99000\n",
        "\n",
        "retinanet = torch.load(path)\n",
        "\n",
        "retinanet = retinanet.cuda()\n",
        "retinanet.eval()\n",
        "\n",
        "mot_tracker= Sort()\n",
        "\n",
        "from skimage import io\n",
        "import skimage\n",
        "from torch.autograd import Variable\n",
        "\n",
        "frames = []\n",
        "frame_count=0\n",
        "mot_tracker = Sort()\n",
        "\n",
        "the_file = open('test_tracking.txt')\n",
        "list_of_test_img = []\n",
        "\n",
        "for line in the_file:\n",
        "  list_of_test_img.append(line.strip())\n",
        "\n",
        "\n",
        "list_of_test_img = sorted(list_of_test_img)\n",
        "\n",
        "all_ = []\n",
        "path = \"/content/Insight-MVT_Annotation_Train/\"\n",
        "s_t=0\n",
        "\n",
        "for id,filename in enumerate(list_of_test_img):\n",
        "\n",
        "    \n",
        "    frame = skimage.io.imread(path+\"/\"+str(filename))\n",
        " \n",
        "    if len(frame.shape) == 2:\n",
        "      frame = skimage.color.gray2rgb(frame)\n",
        "\n",
        "    frame = frame.astype(np.float32)/255.0\n",
        "    frame = torch.from_numpy(frame)\n",
        "    frame = frame.permute(2, 0, 1)\n",
        "    frame = Variable(frame.unsqueeze(0))\n",
        "\n",
        "    height, width = frame.shape[:2]\n",
        "    \n",
        "    \n",
        "    # Bail out when the video file ends\n",
        "           \n",
        "    # Save each frame of the video to a list\n",
        "    scores, classification, transformed_anchors = retinanet(frame.cuda().float())\t\n",
        "    boxes = transformed_anchors.cpu().detach().numpy()\n",
        "    scores_ = scores.cpu().detach().numpy()\n",
        "    s = scores_.reshape(scores_.shape[0],1)\n",
        "    result = np.concatenate((boxes,s), axis=1)\n",
        "    # print(classification)\n",
        "\n",
        "\n",
        "    idxs = np.where(scores.cpu()>0.5)\n",
        "    result_ = np.zeros((len(idxs[0]),5))\n",
        "\n",
        "    for j in range(len(idxs[0])):\n",
        "      result_[j] = result[idxs[0][j], :]\n",
        "\n",
        "    #print(result_)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    if result.size != 0:\n",
        "      #trackers_objects  = mot_tracker.update(detections)\n",
        "      trackers = mot_tracker.update(result_)\n",
        "      s_t += trackers.shape[0]\n",
        "      for d in trackers:\n",
        "            #print(\"d\",d)\n",
        "            xmin=int(d[0])\n",
        "            ymin=int(d[1])\n",
        "            xmax=int(d[2])\n",
        "            ymax=int(d[3])\n",
        "            label=int(d[4])\n",
        "            \n",
        "        # cv2.waitKey(1)\n",
        "\n",
        "            all_.append([filename,label,xmin,ymin,xmax,ymax])\n",
        "      \n",
        "\n",
        "    if(frame_count % 100==0):\n",
        "      print(frame_count,s_t)\n",
        "  \n",
        "  \n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(all_, columns=[\"name\",\"label\",\"x1\",\"y1\",'x2','y2'])\n",
        "df.to_csv('retina_track_out.csv', index=False) \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}